# -*- coding: utf-8 -*-
"""Deep_Neural_Network_Case_Study.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rjylRPHMCm46PN8y1pYySEp_qBSZGDPT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow import keras

print(tf.__version__)

# Load the data from Keras Dataset
fashion_mnist = keras.datasets.fashion_mnist
(train_image, train_labels), (test_image, test_labels) = fashion_mnist.load_data()
print(train_image.shape, test_image.shape, train_labels.shape, test_labels.shape)

class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']

plt.figure()
plt.imshow(train_image[0])
plt.colorbar()
plt.grid(True)
plt.show()

# Min-Max approach (Feature Scaling with image dataset)- Mandatory step in DNN/ANN

from matplotlib import test
train_image = train_image/255.0
test_image = test_image/255.0

plt.figure()
plt.imshow(train_image[0])
plt.colorbar()
plt.grid(True)
plt.show()

plt.figure()
plt.imshow(train_image[0])
plt.colorbar()
plt.grid(False)
plt.show()

# Checking few more images

plt.figure(figsize = (12,12))
for i in range(25):
  plt.subplot(5,5, i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_image[i], cmap=plt.cm.binary)
  plt.xlabel(class_names[train_labels[i]])


plt.show()

"""# Building Multi-Layer_Perceptron Model"""

tf.random.set_seed(100)
tf.keras.backend.clear_session()

model= None

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10)
])

# Summarizing the model

from tensorflow.keras.utils import plot_model
plot_model(model, 'model.png',show_shapes=True)

model.summary()

model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# TensorBoard

import os
import datetime

! rm-rf ./logs/
logdir = os.path.join('logs',datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
print(logdir)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir $logdir

tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

model.fit(train_image, train_labels, epochs=100, callbacks=[tensorboard_callback])

test_loss, test_accuracy = model.evaluate(test_image, test_labels, verbose=2)
print('\nTest Accuracy:', test_accuracy)





